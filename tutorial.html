<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2. Tutorial &mdash; detectree2 1.0.2 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Contributing guide" href="contributing.html" />
    <link rel="prev" title="1. Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            detectree2
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">1. Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">2. Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#preparing-data">2.1. Preparing data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-a-model">2.2. Training a model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#evaluating-model-performance">2.3. Evaluating model performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generating-landscape-predictions">2.4. Generating landscape predictions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">3. Contributing guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-git.html">4. Git/Github</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">detectree2</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><span class="section-number">2. </span>Tutorial</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tutorial.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tutorial">
<h1><span class="section-number">2. </span>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this heading"></a></h1>
<p>A tutorial for:</p>
<ol class="arabic simple">
<li><p>Preparing data</p></li>
<li><p>Training models</p></li>
<li><p>Evaluating model performance</p></li>
<li><p>Making landscape level predictions</p></li>
</ol>
<p>Before getting started ensure <code class="docutils literal notranslate"><span class="pre">detectree2</span></code> is installed through</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp gp-VirtualEnv">(.venv)</span> <span class="gp">$</span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/PatBall1/detectree2.git
</pre></div>
</div>
<p>To train a model you will need an orthomosaic (as <code class="docutils literal notranslate"><span class="pre">&lt;orthmosaic&gt;.tif</span></code>) and
corresponding tree crown polgons that are readable by Geopandas
(e.g. <code class="docutils literal notranslate"><span class="pre">&lt;crowns_polygon&gt;.gpkg</span></code>, <code class="docutils literal notranslate"><span class="pre">&lt;crowns_polygon&gt;.shp</span></code>). For the best
results, manual crowns should be supplied as dense clusters rather than
sparsely scattered across in the landscape</p>
<p>If you would just like to make predictions on an orthomosaic with a pre-trained
model from the <code class="docutils literal notranslate"><span class="pre">model_garden</span></code>, skip to part 4 (Generating landscape predictions).</p>
<section id="preparing-data">
<h2><span class="section-number">2.1. </span>Preparing data<a class="headerlink" href="#preparing-data" title="Permalink to this heading"></a></h2>
<p>An example of the recommended file structure when training a new model is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>├──<span class="w"> </span>Danum<span class="w">                                       </span><span class="o">(</span>site<span class="w"> </span>directory<span class="o">)</span>
│<span class="w">   </span>├──<span class="w"> </span>rgb
│<span class="w">   </span>│<span class="w">   </span>└──<span class="w"> </span>Dan_2014_RGB_project_to_CHM.tif<span class="w">     </span><span class="o">(</span>RGB<span class="w"> </span>orthomosaic<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nb">local</span><span class="w"> </span>UTM<span class="w"> </span>CRS<span class="o">)</span>
│<span class="w">   </span>└──<span class="w"> </span>crowns
│<span class="w">       </span>└──<span class="w"> </span>Danum.gpkg<span class="w">                          </span><span class="o">(</span>Crown<span class="w"> </span>polygons<span class="w"> </span>readable<span class="w"> </span>by<span class="w"> </span>geopandas<span class="w"> </span>e.g.<span class="w"> </span>Geopackage,<span class="w"> </span>shapefile<span class="o">)</span>
│
└──<span class="w"> </span>Paracou<span class="w">                                     </span><span class="o">(</span>site<span class="w"> </span>directory<span class="o">)</span>
<span class="w">    </span>├──<span class="w"> </span>rgb
<span class="w">    </span>│<span class="w">   </span>├──<span class="w"> </span>Paracou_RGB_2016_10cm.tif<span class="w">           </span><span class="o">(</span>RGB<span class="w"> </span>orthomosaic<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nb">local</span><span class="w"> </span>UTM<span class="w"> </span>CRS<span class="o">)</span>
<span class="w">    </span>│<span class="w">   </span>└──<span class="w"> </span>Paracou_RGB_2019.tif<span class="w">                </span><span class="o">(</span>RGB<span class="w"> </span>orthomosaic<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nb">local</span><span class="w"> </span>UTM<span class="w"> </span>CRS<span class="o">)</span>
<span class="w">    </span>└──<span class="w"> </span>crowns
<span class="w">        </span>└──<span class="w"> </span>UpdatedCrowns8.gpkg<span class="w">                 </span><span class="o">(</span>Crown<span class="w"> </span>polygons<span class="w"> </span>readable<span class="w"> </span>by<span class="w"> </span>geopandas<span class="w"> </span>e.g.<span class="w"> </span>Geopackage,<span class="w"> </span>shapefile<span class="o">)</span>
</pre></div>
</div>
<p>Here we have two sites available to train on (Danum and Paracou). Several site directories can be
included in the training and testing phase (but only a single site directory is required).
If available, several RGB orthomosaics can be included in a single site directory (see e.g <code class="docutils literal notranslate"><span class="pre">Paracou</span> <span class="pre">-&gt;</span> <span class="pre">RGB</span></code>).</p>
<p>We call functions to from <code class="docutils literal notranslate"><span class="pre">detectree2</span></code>’s tiling and training modules.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectree2.preprocessing.tiling</span> <span class="kn">import</span> <span class="n">tile_data_train</span><span class="p">,</span> <span class="n">to_traintest_folders</span>
<span class="kn">from</span> <span class="nn">detectree2.models.train</span> <span class="kn">import</span> <span class="n">register_train_data</span><span class="p">,</span> <span class="n">MyTrainer</span><span class="p">,</span> <span class="n">setup_cfg</span>
<span class="kn">import</span> <span class="nn">rasterio</span>
<span class="kn">import</span> <span class="nn">geopandas</span> <span class="k">as</span> <span class="nn">gpd</span>
</pre></div>
</div>
<p>Set up the paths to the orthomosaic and corresponding manual crown data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up input paths</span>
<span class="n">site_path</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/data/Paracou&quot;</span>
<span class="n">img_path</span> <span class="o">=</span> <span class="n">site_path</span> <span class="o">+</span> <span class="s2">&quot;/rgb/2016/Paracou_RGB_2016_10cm.tif&quot;</span>
<span class="n">crown_path</span> <span class="o">=</span> <span class="n">site_path</span> <span class="o">+</span> <span class="s2">&quot;/crowns/220619_AllSpLabelled.gpkg&quot;</span>

<span class="c1"># Read in the tiff file</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">rasterio</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>

<span class="c1"># Read in crowns (then filter by an attribute if required)</span>
<span class="n">crowns</span> <span class="o">=</span> <span class="n">gpd</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">crown_path</span><span class="p">)</span>
<span class="n">crowns</span> <span class="o">=</span> <span class="n">crowns</span><span class="o">.</span><span class="n">to_crs</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">crs</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="c1"># making sure CRS match</span>
</pre></div>
</div>
<p>Set up the tiling parameters.</p>
<p>The tile size will depend on:</p>
<ul class="simple">
<li><p>The resolution of your imagery.</p></li>
<li><p>Available computational resources.</p></li>
<li><p>The detail required on the crown outline.</p></li>
<li><p>If using a pre-trained model, the tile size used in training should roughly match the tile size of predictions.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set tiling parameters</span>
<span class="n">buffer</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">tile_width</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">tile_height</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.6</span>
<span class="n">appends</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">tile_width</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span> <span class="c1"># this helps keep file structure organised</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="n">site_path</span> <span class="o">+</span> <span class="s2">&quot;/tiles_&quot;</span> <span class="o">+</span> <span class="n">appends</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span>
</pre></div>
</div>
<p>The total tile size here is 100 m x 100 m (a 40 m x 40 m core area with a surrounding 30 m buffer that overlaps with
surrounding tiles). Including a buffer is recommended as it allows for tiles that include more training crowns.</p>
<p>Next we tile the data. The <code class="docutils literal notranslate"><span class="pre">tile_data_train</span></code> function will only retain tiles that contain more than the given
<code class="docutils literal notranslate"><span class="pre">threshold</span></code> coverage of training data (here 60%). This helps to reduce the chance that the network is trained with
tiles that contain a large number of unlabelled crowns (which would reduce its sensitivity).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tile_data_train</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">out_dir</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">tile_width</span><span class="p">,</span> <span class="n">tile_height</span><span class="p">,</span> <span class="n">crowns</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If tiles are outputing as blank images set <code class="docutils literal notranslate"><span class="pre">dtype_bool</span> <span class="pre">=</span> <span class="pre">True</span></code> in the <code class="docutils literal notranslate"><span class="pre">tile_data_train</span></code> function. This is a bug
and we are working on fixing it.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You will want to relax the <code class="docutils literal notranslate"><span class="pre">threshold</span></code> value if your trees are sparsely distributed across your landscape.
Remember, <code class="docutils literal notranslate"><span class="pre">detectree2</span></code> was initially designed for dense, closed canopy forests so some of the default assumptions
will reflect that.</p>
</div>
<p>Send geojsons to train folder (with sub-folders for k-fold cross validation) and test folder.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_folder</span> <span class="o">=</span> <span class="n">out_dir</span> <span class="c1"># data_folder is the folder where the .png, .tif, .geojson tiles have been stored</span>
<span class="n">to_traintest_folders</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">out_dir</span><span class="p">,</span> <span class="n">test_frac</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">folds</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">to_traintest_folders</span></code> function automatically removes training/validation geojsons that overlap with test
tiles, ensuring strict spatial separation of the test data. However, this can remove a significant proportion of the
data available to train on so if validation accuracy is a sufficient test of model performance <code class="docutils literal notranslate"><span class="pre">test_frac</span></code> can be
set to <code class="docutils literal notranslate"><span class="pre">0</span></code>. Alternatively, just set a <code class="docutils literal notranslate"><span class="pre">test_frac</span></code> value that is smaller than you might otherwise have put.</p>
</div>
<p>The data has now been tiled and partitioned for model training, tuning and evaluation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>└── Danum                                       (site directory)
    ├── rgb
    │   └── Dan_2014_RGB_project_to_CHM.tif     (RGB orthomosaic in local UTM CRS)
    ├── crowns
    │   └── Danum.gpkg
    └── tiles                                   (tile directory)
        ├── train
        │   ├── fold_1                          (train/val fold folder)
        │   ├── fold_2                          (train/val fold folder)
        │   └── ...
        └── test                                (test data folder)
</pre></div>
</div>
<p>It is advisable to do a visual inspection on the tiles to ensure that the tiling has worked as expected and that crowns
and images align. This can be done quickly with the inbuilt <code class="docutils literal notranslate"><span class="pre">detectron2</span></code> visualisation tools.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">DatasetCatalog</span><span class="p">,</span> <span class="n">MetadataCatalog</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">Visualizer</span>
<span class="kn">from</span> <span class="nn">detectree2.models.train</span> <span class="kn">import</span> <span class="n">combine_dicts</span><span class="p">,</span> <span class="n">register_train_data</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Danum&quot;</span>
<span class="n">train_location</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/data/&quot;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;/tiles_&quot;</span> <span class="o">+</span> <span class="n">appends</span> <span class="o">+</span> <span class="s2">&quot;/train&quot;</span>
<span class="n">dataset_dicts</span> <span class="o">=</span> <span class="n">combine_dicts</span><span class="p">(</span><span class="n">train_location</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># The number gives the fold to visualise</span>
<span class="n">trees_metadata</span> <span class="o">=</span> <span class="n">MetadataCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_train&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dataset_dicts</span><span class="p">:</span>
   <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;file_name&quot;</span><span class="p">])</span>
   <span class="n">visualizer</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">metadata</span><span class="o">=</span><span class="n">trees_metadata</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
   <span class="n">out</span> <span class="o">=</span> <span class="n">visualizer</span><span class="o">.</span><span class="n">draw_dataset_dict</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
   <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_image</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
   <span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../../report/figures/trees_train1.jpg"><img alt="Prediction" class="align-left" src="../../report/figures/trees_train1.jpg" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="../../report/figures/trees_train2.jpg"><img alt="Prediction" class="align-left" src="../../report/figures/trees_train2.jpg" style="width: 400px;" /></a>
</section>
<section id="training-a-model">
<h2><span class="section-number">2.2. </span>Training a model<a class="headerlink" href="#training-a-model" title="Permalink to this heading"></a></h2>
<p>Before training can commence, it is necessary to register the training data. It is possible to set a validation fold for
model evaluation (which can be helpful for tuning models). The validation fold can be changed over different training
steps to expose the model to the full range of available training data. Register as many different folders as necessary</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_location</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/data/Danum/tiles_&quot;</span> <span class="o">+</span> <span class="n">appends</span> <span class="o">+</span> <span class="s2">&quot;/train/&quot;</span>
<span class="n">register_train_data</span><span class="p">(</span><span class="n">train_location</span><span class="p">,</span> <span class="s1">&#39;Danum&#39;</span><span class="p">,</span> <span class="n">val_fold</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">train_location</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/data/Paracou/tiles_&quot;</span> <span class="o">+</span> <span class="n">appends</span> <span class="o">+</span> <span class="s2">&quot;/train/&quot;</span>
<span class="n">register_train_data</span><span class="p">(</span><span class="n">train_location</span><span class="p">,</span> <span class="s2">&quot;Paracou&quot;</span><span class="p">,</span> <span class="n">val_fold</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>The data will be registered as <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;_train</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;_val</span></code> (or <code class="docutils literal notranslate"><span class="pre">Paracou_train</span></code> and <code class="docutils literal notranslate"><span class="pre">Paracou_val</span></code> in the
above example). It will be necessary to supply these registation names below…</p>
<p>We must supply a <code class="docutils literal notranslate"><span class="pre">base_model</span></code> from Detectron2’s  <code class="docutils literal notranslate"><span class="pre">model_zoo</span></code>. This loads a backbone that has been pre-trained which
saves us the pain of training a model from scratch. We are effectively transferring this model and (re)training it on
our problem for the sake of time and efficiency. The <cite>trains</cite> and <cite>tests</cite> variables containing the registered datasets
should be tuples containing strings. If just a single site is being used a comma should still be supplied (e.g.
<code class="docutils literal notranslate"><span class="pre">trains</span> <span class="pre">=</span> <span class="pre">(&quot;Paracou_train&quot;,)</span></code>) otherwise the data loader will malfunction.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the base (pre-trained) model from the detectron2 model_zoo</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml&quot;</span>

<span class="n">trains</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Paracou_train&quot;</span><span class="p">,</span> <span class="s2">&quot;Danum_train&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokEast_train&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokWest_train&quot;</span><span class="p">)</span> <span class="c1"># Registered train data</span>
<span class="n">tests</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Paracou_val&quot;</span><span class="p">,</span> <span class="s2">&quot;Danum_val&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokEast_val&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokWest_val&quot;</span><span class="p">)</span> <span class="c1"># Registered validation data</span>

<span class="n">out_dir</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/220809_train_outputs&quot;</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">setup_cfg</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">trains</span><span class="p">,</span> <span class="n">tests</span><span class="p">,</span> <span class="n">workers</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">eval_period</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">out_dir</span><span class="o">=</span><span class="n">out_dir</span><span class="p">)</span> <span class="c1"># update_model arg can be used to load in trained  model</span>
</pre></div>
</div>
<p>Alternatively, it is possible to train from one of <code class="docutils literal notranslate"><span class="pre">detectree2</span></code>’s pre-trained models. This is normally recommended and
especially useful if you only have limited training data available. To retrieve the model from the repo’s
<code class="docutils literal notranslate"><span class="pre">model_garden</span></code> run e.g.:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!wget https://github.com/PatBall1/detectree2/raw/master/model_garden/230103_randresize_full.pth
</pre></div>
</div>
<p>Then set up the configurations as before but with the trained model also supplied:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the base (pre-trained) model from the detectron2 model_zoo</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml&quot;</span>

<span class="c1"># Set the updated model weights from the detectree2 pre-trained model</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="s2">&quot;./230103_randresize_full.pth&quot;</span>

<span class="n">trains</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Paracou_train&quot;</span><span class="p">,</span> <span class="s2">&quot;Danum_train&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokEast_train&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokWest_train&quot;</span><span class="p">)</span> <span class="c1"># Registered train data</span>
<span class="n">tests</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Paracou_val&quot;</span><span class="p">,</span> <span class="s2">&quot;Danum_val&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokEast_val&quot;</span><span class="p">,</span> <span class="s2">&quot;SepilokWest_val&quot;</span><span class="p">)</span> <span class="c1"># Registered validation data</span>

<span class="n">out_dir</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/220809_train_outputs&quot;</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">setup_cfg</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">trains</span><span class="p">,</span> <span class="n">tests</span><span class="p">,</span> <span class="n">trained_model</span><span class="p">,</span> <span class="n">workers</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">eval_period</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">out_dir</span><span class="o">=</span><span class="n">out_dir</span><span class="p">)</span> <span class="c1"># update_model arg used to load in trained model</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may want to experiment with how you set up the <code class="docutils literal notranslate"><span class="pre">cfg</span></code>. The variables can make a big difference to how quickly
model training will converge given the particularities of the data supplied and computational resources available.</p>
</div>
<p>Once we are all set up, we can get commence model training. Training will continue until a specified number of
iterations (<code class="docutils literal notranslate"><span class="pre">max_iter</span></code>) or until model performance is no longer improving (“early stopping” via <code class="docutils literal notranslate"><span class="pre">patience</span></code>).
Training outputs, including model weights and training metrics, will be stored in <code class="docutils literal notranslate"><span class="pre">out_dir</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">MyTrainer</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">resume_or_load</span><span class="p">(</span><span class="n">resume</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Early stopping is implemented and will be triggered by a sustained failure to improve on the performance of
predictions on the validation fold. This is measured as the AP50 score of the validation predictions.</p>
</div>
</section>
<section id="evaluating-model-performance">
<h2><span class="section-number">2.3. </span>Evaluating model performance<a class="headerlink" href="#evaluating-model-performance" title="Permalink to this heading"></a></h2>
<p>Coming soon! See Colab notebook for example routine (<code class="docutils literal notranslate"><span class="pre">detectree2/notebooks/colab/evaluationJB.ipynb</span></code>).</p>
</section>
<section id="generating-landscape-predictions">
<h2><span class="section-number">2.4. </span>Generating landscape predictions<a class="headerlink" href="#generating-landscape-predictions" title="Permalink to this heading"></a></h2>
<p>Here we call the necessary functions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectree2.preprocessing.tiling</span> <span class="kn">import</span> <span class="n">tile_data</span>
<span class="kn">from</span> <span class="nn">detectree2.models.outputs</span> <span class="kn">import</span> <span class="n">project_to_geojson</span><span class="p">,</span> <span class="n">stitch_crowns</span><span class="p">,</span> <span class="n">clean_crowns</span>
<span class="kn">from</span> <span class="nn">detectree2.models.predict</span> <span class="kn">import</span> <span class="n">predict_on_data</span>
<span class="kn">from</span> <span class="nn">detectree2.models.train</span> <span class="kn">import</span> <span class="n">setup_cfg</span>
<span class="kn">from</span> <span class="nn">detectron2.engine</span> <span class="kn">import</span> <span class="n">DefaultPredictor</span>
<span class="kn">import</span> <span class="nn">rasterio</span>
</pre></div>
</div>
<p>Start by tiling up the entire orthomosaic so that a crown map can be made for the entire landscape. Tiles should be
approximately the same size as those trained on (typically ~ 100 m). A buffer (here 30 m) should be included so that we
can discard partial the crowns predicted at the edge of tiles.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Path to site folder and orthomosaic</span>
<span class="n">site_path</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/data/BCI_50ha&quot;</span>
<span class="n">img_path</span> <span class="o">=</span> <span class="n">site_path</span> <span class="o">+</span> <span class="s2">&quot;/rgb/2015.06.10_07cm_ORTHO.tif&quot;</span>
<span class="n">tiles_path</span> <span class="o">=</span> <span class="n">site_path</span> <span class="o">+</span> <span class="s2">&quot;/tilespred/&quot;</span>
<span class="c1"># Read in the geotiff</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">rasterio</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
<span class="c1"># Location of trained model</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/Shareddrives/detectree2/models/220629_ParacouSepilokDanum_JB.pth&quot;</span>

<span class="c1"># Specify tiling</span>
<span class="n">buffer</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">tile_width</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">tile_height</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">tile_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">tiles_path</span><span class="p">,</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">tile_width</span><span class="p">,</span> <span class="n">tile_height</span><span class="p">,</span> <span class="n">dtype_bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If tiles are outputing as blank images set <code class="docutils literal notranslate"><span class="pre">dtype_bool</span> <span class="pre">=</span> <span class="pre">True</span></code> in the <code class="docutils literal notranslate"><span class="pre">tile_data</span></code> function. This is a bug
and we are working on fixing it.</p>
</div>
<p>To download a pre-trained model from the <code class="docutils literal notranslate"><span class="pre">model_garden</span></code> you can run <code class="docutils literal notranslate"><span class="pre">wget</span></code> on the package repo</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!wget https://github.com/PatBall1/detectree2/raw/master/model_garden/230103_randresize_full.pth
</pre></div>
</div>
<p>Point to a trained model, set up the configuration state and make predictions on the tiles.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trained_model</span> <span class="o">=</span> <span class="s2">&quot;./230103_randresize_full.pth&quot;</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">setup_cfg</span><span class="p">(</span><span class="n">update_model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">)</span>
<span class="n">predict_on_data</span><span class="p">(</span><span class="n">tiles_path</span><span class="p">,</span> <span class="n">DefaultPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">))</span>
</pre></div>
</div>
<p>Once the predictions have been made on the tiles, it is necessary to project them back into geographic space.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">project_to_geojson</span><span class="p">(</span><span class="n">tiles_path</span><span class="p">,</span> <span class="n">tiles_path</span> <span class="o">+</span> <span class="s2">&quot;predictions/&quot;</span><span class="p">,</span> <span class="n">tiles_path</span> <span class="o">+</span> <span class="s2">&quot;predictions_geo/&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>To create a useful outputs it is necessary to stitch the crowns together while handling overlaps in the buffer.
Invalid geometries may arise when converting from a mask to a polygon - it is usually best to simply remove these.
Cleaning the crowns will remove instances where there is large overlaps between predicted crowns (removing the
predictions with lower confidence).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">crowns</span> <span class="o">=</span> <span class="n">stitch_crowns</span><span class="p">(</span><span class="n">tiles_path</span> <span class="o">+</span> <span class="s2">&quot;predictions_geo/&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">clean</span> <span class="o">=</span> <span class="n">clean_crowns</span><span class="p">(</span><span class="n">crowns</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># set a confidence&gt;0 to filter out less confident crowns</span>
</pre></div>
</div>
<p>By default the <code class="docutils literal notranslate"><span class="pre">clean_crowns</span></code> function will remove crowns with a condidence of less than 20%. The above ‘clean’ crowns
includes crowns of all confidence scores (0%-100%) as <code class="docutils literal notranslate"><span class="pre">condidence=0</span></code>. It is likely that crowns with very low
confidence will be poor quality so it is usually preferable to filter these out. A suitable threshold can be determined
by eye in QGIS or implemented as single line in Python. <code class="docutils literal notranslate"><span class="pre">Confidence_score</span></code> is a column in the <code class="docutils literal notranslate"><span class="pre">crowns</span></code> GeoDataFrame
and is considered a tunable parameter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clean</span> <span class="o">=</span> <span class="n">clean</span><span class="p">[</span><span class="n">clean</span><span class="p">[</span><span class="s2">&quot;Confidence_score&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="c1"># step included for illustration - can be done in clean_crowns func</span>
</pre></div>
</div>
<p>The outputted crown polygons will have many vertices because they are generated from a mask which is pixelwise. If you
will need to edit the crowns in QGIS it is best to simplify them to a reasonable number of vertices. This can be done
with <code class="docutils literal notranslate"><span class="pre">simplify</span></code> method. The <code class="docutils literal notranslate"><span class="pre">tolerance</span></code> will determine the coarseness of the simplification it has the same units as
the coordinate reference system of the GeoSeries (meters when working with UTM).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clean</span> <span class="o">=</span> <span class="n">clean</span><span class="o">.</span><span class="n">set_geometry</span><span class="p">(</span><span class="n">crowns</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
</pre></div>
</div>
<p>Once we’re happy with the crown map, save the crowns to file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clean</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="n">site_path</span> <span class="o">+</span> <span class="s2">&quot;/crowns_out.gpkg&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>View the file in QGIS or ArcGIS to see whether you are satisfied with the results. The first output might not be perfect
and so tweaking of the above parameters may be necessary to get a satisfactory output.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="1. Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="contributing.html" class="btn btn-neutral float-right" title="3. Contributing guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, James Ball.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>